<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Yu Sun</title>
  <!-- Bulma Version-->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
  <link rel="icon" sizes="72x72" href="images/apple-touch-icon-72x72.png" type="image/png"/>
  <script src="js/menuspy.js"></script>

  <!--  css-->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.10.0/css/all.css"
        integrity="sha384-AYmEC3Yw5cVb3ZcuHtOA93w35dYTsvhLPVnYs9eStHfGJvOvKxVfELGroGkvsg+p" crossorigin="anonymous"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="css/style.css" rel="stylesheet" type="text/css">
  <link href="css/css.css" rel="stylesheet">
  <link href="css/svg.css" rel="stylesheet" type="text/css">
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2">
          <div class="sticky">
            <figure class="image is-128x128">
              <img class="is-rounded" src="images/syphoto1.png">
            </figure>
            <div class="content">
              <h3>Yu Sun</h3>
              <h6>孙宇</h6>
              <h6>Ph.D.</h6>
              <h6>UNSW Sydney</h6>
            </div>
            <!-- details -->
            <div class="details">
              <h3>EMAIL</h3>
              <p><a href="mailto:sunyucq@163.com">sunyucq<br>[at]163[dot]com</a></p>
            </div>
            <!-- social network icons -->
            <div class="social">
              <a href="https://github.com/SunyuGo" target="_blank">
                <i class="fab fa-github-square svg-inline--fa fa-w-16 fa-2x"></i>
              </a>
              <a href="https://scholar.google.com/citations?user=5NdPrUgAAAAJ&hl=en" target="_blank">
                <i class="ai ai-google-scholar-square svg-inline--fa fa-w-16 fa-2x"></i>
              </a>
              <a href="https://www.linkedin.com/in/sfhan/" target="_blank">
                <i class="fab fa-twitter-square svg-inline--fa fa-w-16 fa-2x"></i>
              </a>
              <!--<a href="https://www.facebook.com/tianweishen.shen" target="_blank">-->
                <!--<span class="fab fa-facebook fa-2x" style="display:inline; text-decoration: none"></span>-->
              <!--</a>-->
              <!--<a href="https://twitter.com/HegongEngineer" target="_blank">-->
                <!--<span class="fab fa-twitter fa-2x" style="display:inline; text-decoration: none"></span>-->
              <!--</a>-->
            </div>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <p class="menu-label"><b>Quick Links</b></p>
              <ul class="menu-list">
                <li><a href="#bio">Bio</a></li>
                <li><a href="#research" class="is-active">Publication</a></li>
                <li><a href="#news">News</a></li>
                <li><a href="#professional">Professional Activities</a></li>
              </ul>
            </div>
          </div>



        </div>
        <div class="column">
          <div class="content">

            <!--Bio-->
            <h3 id="bio">Bio</h3>
            <p>Welcome to my site！I’m a first-year robotics PhD candidate at the 
              University of New South Wales’s School of Mechanical and Manufacturing Engineering, co-advised by 
              <a href="https://www.drliaowu.com" target="_blank" style="text-decoration: underline;">Dr. Leo Wu</a> 
              and <a href="https://www.unsw.edu.au/staff/jay-katupitiya" target="_blank" style="text-decoration: underline;">Prof. Jay Katupitiya</a>. 
              My research interest lies in the areas of Medical Robotics, such as Flexible Robots for Autonomous Minimally Invasive Surgery 
              and Assistive Robots with Artificial Muscles and Wearable Sensors. I’m funded through the University 
              International Postgraduate Award.
              
            <br/><br/>
            
              Prior to joining UNSW, I earned my Bachelor’s degree from the School of Vehicle Engineering at 
              Chongqing University of Technology and Master’s degree from the College of Mechanical and Vehicle Engineering at 
              Chongqing University where I started my research on Multibody Dynamics and Machine Learning with
               <a href="https://faculty.cqu.edu.cn/YongjunPan/zh_CN/index/338379/list/index.htm" target="_blank" style="text-decoration: underline;">Prof. Yongjun Pan</a>.
            </p>
            [<a href = "files/CV.pdf">CV</a>].<br/><br/>


            <!--Research-->
            <h3 id="research">Publications</h3>

            <article class="columns">
              <div class="column is-3">
                <picture class="image">
                  <img src="images/research/2022-VSD1.png">
                </picture>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Maneuver-based deep learning parameter
                      identification of vehicle suspensions subjected to
                      performance degradation</b><br>
                    Yongjun Pan, <strong>Yu Sun</strong>, Chuan Min, Zhixiong Li and Paolo Gardoni.<br>
                    <em>Vehicle System Dynamics, 2021</em><br>
                    <a href="publications/2022-VSD1.pdf" target="_blank">[<u>paper</u>]</a>
                    <a href="https://www.tandfonline.com/doi/full/10.1080/00423114.2022.2084424" target="_blank">[<u>link</u>]</a>
                  </p>
                </div>
              </div>
            </article>           

            <article class="columns">
              <div class="column is-3">
                <picture class="image">
                  <source type="image/avif" srcset="img/avif/visual_tactile.avif"/>
                  <img src="img/visual_tactile.gif" alt="file missing">
                </picture>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Robot Synesthesia: In-Hand Manipulation with Visuotactile Sensing</b><br>
                    Ying Yuan*, Haichuan Che*, <strong>Yuzhe Qin*</strong>, Binghao Huang, Zhao-Heng Yin, <br>
                    Kang-Won Lee, Yi Wu, Soo-Chul Lim, Xiaolong Wang <br>
                    <em>arXiv, 2023</em><br>
                    <a href="https://yingyuan0414.github.io/visuotactile/" target="_blank">[<u>project</u>]</a>
                    <a href="https://arxiv.org/abs/2312.01853" target="_blank">[<u>paper</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <h4>2021</h4>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/noisy_label.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Learning with Noisy Labels for Robust Point Cloud Segmentation</i><br>
                    Shuquan Ye, Dongdong Chen, <b>Songfang Han</b>, Jing Liao.<br>
                    International Conference on Computer Vision (ICCV Oral), 2021<br>
                    <a href="https://shuquanye.com/PNAL_website/" target="_blank">[<u>project (code)</u>]</a>
                    <a href="https://arxiv.org/abs/2107.14230" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/pleaseconnectwifi/PNAL" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/m3d-vton.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>M3D-VTON: A Monocular-to-3D Virtual Try-On Network</i><br>
                    Fuwei Zhao, Zhenyu Xie, Michael Kampffmeyer, Haoye Dong, <b>Songfang Han</b>, Tianxiang Zheng, Tao Zhang, Xiaodan Liang.<br>
                    International Conference on Computer Vision (ICCV), 2021.<br>
<!--                    <a href="https://shuquanye.com/PNAL_website/" target="_blank">[<u>project (code)</u>]</a>-->
                    <a href="https://arxiv.org/abs/2108.05126" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/fyviezhao/m3d-vton" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/compnet.gif">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Compositionally Generalizable 3D Structure Prediction</i><br>
                    <b>Songfang Han</b>, Jiayuan Gu, Kaichun Mo, Li Yi, Siyu Hu, Xuejin Chen, Hao Su.<br>
                    arXiv, 2021.<br>
<!--                    <a href="https://github.com/pleaseconnectwifi/Meta-PU" target="_blank">[<u>project (code)</u>]</a>-->
                    <a href="https://arxiv.org/abs/2012.02493" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/hansongfang/CompNet" target="_blank">[<u>code</u>]</a>
                    <a href="https://youtu.be/a1Mghtz3erM" target="_blank">[<u>video</u>]</a><br>
<!--                    We bring in the concept of compositional generalizability and factorizes the 3D shape reconstruction problem into proper sub-problems, each of which is tackled by a carefully designed neural sub-module with generalizability guarantee. Experiments on PartNet show that we achieve superior performance than baseline methods, which validates our problem factorization and network designs.-->
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/teaser_tvcg21.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Arbitrary-Scale Upsampling Network for Point Cloud</i><br>
                    Shuquan Ye, Dongdong Chen, <b>Songfang Han</b>, Ziyu Wan, Jing Liao.<br>
                    Visualization and Computer Graphics (TVCG), 2021. <br>
                    <a href="https://github.com/pleaseconnectwifi/Meta-PU" target="_blank">[<u>project (code)</u>]</a>
                    <a href="https://ieeexplore.ieee.org/document/9351772/" target="_blank">[<u>paper</u>]</a><br>
                  </p>
                </div>
              </div>
            </article>

            <h4>2020</h4>
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/PMVS.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Visibility-Aware Point-Based Multi-View Stereo Network</i><br>
                    Rui Chen, <b>Songfang Han</b>, Jing Xu.<br>
                    TPAMI 2020 Apr 22. doi: 10.1109/TPAMI.2020.2988729.<br>
                    <a href="https://github.com/callmeray/PointMVSNet" target="_blank">[<u>project (code)</u>]</a>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9076298" target="_blank">[<u>paper</u>]</a><br>
                    This is an extension of our ICCV work (Point-based Multi-view Stereo Network). In this paper, we introduce visibility-aware multi-view feature aggregation modules to gather information from visible views only for better depth prediction accuracy.
                  </p>
                </div>
              </div>
            </article>

            <h4>2019</h4>
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/2019_pmvsnet_s.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Point-Based Multi-View Network</i><br>
                    <b>Songfang Han*</b>, Rui Chen*, Jing Xu, Hao Su.<br>
                    ICCV 2019 (oral).<br>
                    <a href="projects/PMVSNet/index.html" target="_blank">[<u>project (code)</u>]</a>
                    <a href="https://arxiv.org/pdf/1908.04422.pdf" target="_blank">[<u>paper</u>]</a>
                    <a href="https://www.youtube.com/watch?v=eSBFOD5rDsU" target="_blank">[<u>video</u>]</a><br>
                    An iterative framework to predict the depth of a scene using point cloud representation from multiple views. Use deep learning over the kNN graph to predict the residual for geometry estimation refinement.
                  </p>
                </div>
              </div>
            </article>

            <h4>2018</h4>
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/2018_reorder_s.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>In-Depth Buffers</i><br>
                    <b>Songfang Han</b>, Ge Chen, Diego Nehab, Pedro Sander.<br>
                    Proceedings of the ACM on Computer Graphics and Interactive Techniques (PACM) 2018.<br>
                    <a href="files/2018Reorder.pdf" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/hansongfang/idb" target="_blank">[<u>code</u>]</a>
                    <a href="https://youtu.be/bIr7gOWNPKE" target="_blank">[<u>video</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <h4>2017</h4>
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/2017_reorder_s.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Triangle Reordering for Efficient Rendering in Complex Scenes </i><br>
                    <b>Songfang Han</b>, Pedro Sander.<br>
                    The Journal of Computer Graphics Techniques (JCGT) 2017.<br>
                    <a href="files/Han2017Reordering.pdf" target="_blank">[<u>paper</u>]</a>
                    <a href="http://jcgt.org/published/0006/03/03/code.zip" target="_blank">[<u>code</u>]</a>
                    <a href="http://jcgt.org/published/0006/03/03/JCGT.mp4" target="_blank">[<u>video</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <h4>2016</h4>
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/research/2016_reorder_s.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <i>Triangle Reordering for Reduced Overdraw in Animated Scenes </i><br>
                    <b>Songfang Han</b>, Pedro Sander.<br>
                    Proceedings of the 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) 2016.<br>
                    <a href="files/2016Reorder.pdf" target="_blank">[<u>paper</u>]</a>
                    <!--<a href="http://jcgt.org/published/0006/03/03/JCGT.mp4" target="_blank">[<u>video</u>]</a>-->
                  </p>
                </div>
              </div>
            </article>

            <!--News-->
            <h3 id="news">
              News
            </h3>
            <ul>
              <li><span>Feb, 2024 - One paper get accepted to MSD.</span></li>
              <li><span>Nov, 2023 - Has been admitted to UNSW (UIPA).</span></li>
              <li><span>Oct, 2023 - One paper gets accepted to EAAI.</span></li>
              <li><span>June, 2023 - Has successfully got my Master’s degree (Outstanding)!</span></li>
              <li><span>May, 2023 - Has successfully defended my Master’s thesis!</span></li>
              <li><span>Oct, 2022 - One paper gets accepted to RESS.</span></li>
              <li><span>Apr, 2022 - One paper gets accepted to VSD.</span></li>
              <li><span>May, 2020 - Has been admitted to CQU.</span></li>
            </ul>
            
            <h3 id="professional">Professional Activities</h3>
            <ul>
              <li>Workshop Organizer: <a href="https://learn-dex-hand.github.io/rss2023/" target="_blank">Learning
                Dexterous Manipulation</a> @RSS 2023;
              <li>Tutorial Organizer: <a
                  href="https://ai-workshops.github.io/building-and-working-in-environments-for-embodied-ai-cvpr-2022/"
                  target="_blank">
                Building and Working in Environments for Embodied AI</a> @CVPR 2022;
              </li>
              <li>Challenge Organizer: <a href="http://www.ocrtoc.org" target="_blank">Open Cloud Robot Table
                Organization Challenge (OCRTOC)</a> @IROS 2020, @ICRA 2021;
              </li>
              <li>Conference Reviewer: CVPR, ICCV, ECCV, RSS, CoRL, ICRA, IROS, SIGGRAPH, AAAI, ICML, ICLR, NeurIPS
              </li>
              <li>Journal Reviewer: RA-L, IJRR, T-PAMI, JMLR, PRL</li>
            </ul>            
          </div>
          <br>
          <p style="text-align:left;font-size:small;">
            Credit: web source from <a href="http://hansf.me">Dr. Songfang Han</a> and <a href="https://yzqin.github.io/"> Yuzhe Qin</a>
          </p>          
        </div>
      </div>
    </div>
  </section>

  <script>
    var elm = document.querySelector('#sidebar');
    var ms = new MenuSpy(elm, {
      activeClass: 'is-active'
    });
  </script>
</body>

</html>